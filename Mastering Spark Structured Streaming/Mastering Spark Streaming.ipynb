{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8f82024-862e-49e7-83da-69ffbb5dab97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d4d1fc7-7c3e-4959-8cf5-00129ec764f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Preparing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69b69356-2aba-4ea4-99d9-87cd29a55a34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Use catalog learn_adb_fikrat;\n",
    "create schema if not exists bronze;\n",
    "create schema if not exists silver;\n",
    "Use bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ade5d9-c043-4e7e-9195-c7e1dd777bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DROP TABLE IF EXISTS bronze.iot_measurements;\n",
    "-- DROP TABLE IF EXISTS weather;\n",
    "-- DROP TABLE IF EXISTS office;\n",
    "-- DROP TABLE IF EXISTS iot_pivoted;\n",
    "-- DROP TABLE IF EXISTS silver.iot_measurements;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3abdeaff-2d0e-4596-9b22-31d59ee773e1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Defining variables"
    }
   },
   "outputs": [],
   "source": [
    "root_data_folder='/Volumes/learn_adb_fikrat/bronze/landing'\n",
    "\n",
    "checkpoint_root_path = \"/Volumes/learn_adb_fikrat/bronze/ext_landing_volume/streaming-checkpoints\"\n",
    "\n",
    "checkpoint_path_sensor=f'{checkpoint_root_path}/iot_measurements'\n",
    "checkpoint_path_sensor1=f'{checkpoint_root_path}/iot_measurements1'\n",
    "checkpoint_path_sensor2=f'{checkpoint_root_path}/iot_measurements2'\n",
    "checkpoint_path_sensor3=f'{checkpoint_root_path}/iot_measurements3'\n",
    "checkpoint_path_sensor4=f'{checkpoint_root_path}/iot_measurements4'\n",
    "checkpoint_path_sensor5=f'{checkpoint_root_path}/iot_measurements5'\n",
    "checkpoint_path_sensor6=f'{checkpoint_root_path}/iot_measurements6'\n",
    "checkpoint_path_sensor7=f'{checkpoint_root_path}/iot_measurements7'\n",
    "checkpoint_path_sensor8=f'{checkpoint_root_path}/iot_measurements8'\n",
    "checkpoint_path_weather=f'{checkpoint_root_path}/weather'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ebcf3ee-6a03-48ec-bae6-dc8a0ae2e5ea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cleanse checkpointing folders"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(checkpoint_path_weather, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor1, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor2, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor3, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor4, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor5, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor6, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor7, True)\n",
    "dbutils.fs.rm(checkpoint_path_sensor8, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "784b6b7a-1790-474a-8956-034be678f808",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read/write office data"
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format('csv').option('header','true').load(f'{root_data_folder}/office')\\\n",
    "  .write.format('delta').mode('overwrite').saveAsTable('bronze.office')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d75903fc-7855-4604-b6ff-cbcd90b0ab70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Basic streaming operations: read and write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b650d0b-d415-4dc3-9f04-ef72e1db1416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Basic read/write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6947229f-b79c-4ba8-b818-30a37bbca440",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Preparing schema"
    }
   },
   "outputs": [],
   "source": [
    "iot_schema =StructType([StructField('EventTime', StringType(), True), \n",
    "                        StructField('Measurements', \n",
    "                            StructType(\n",
    "                                [StructField('MeasurementType', StringType(), True), \n",
    "                                StructField('MeasurementValue', DoubleType(), True), \n",
    "                                StructField('Sensor', StringType(), True)]), \n",
    "                        True), \n",
    "                        StructField('Office', StringType(), True)])\n",
    "weather_schema =StructType([StructField('City', StringType(), True), \n",
    "                            StructField('EventTime', StringType(), True), \n",
    "                            StructField('Temperature', DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a91ab5e-21b6-42e0-9b1b-2e538bc801cb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading stream"
    }
   },
   "outputs": [],
   "source": [
    "dfSensor = spark.readStream.format('json') \\\n",
    "    .schema(iot_schema) \\\n",
    "    .load(f'{root_data_folder}/sensor')\\\n",
    "    .withColumn('IngestionTimestamp', F.current_timestamp())\\\n",
    "    .withColumn('SourceFileName', F.input_file_name() )    \n",
    "\n",
    "# display(dfSensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59c5a66b-0eb0-4ec4-bce5-aa50ec30cb5c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Writing sensor data to Delta table"
    }
   },
   "outputs": [],
   "source": [
    "strms=dfSensor.writeStream.format(\"delta\")\\\n",
    "    .queryName('iot_measurements')\\\n",
    "    .option('checkpointLocation', checkpoint_path_sensor)\\\n",
    "    .toTable('bronze.iot_measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "578be266-5a19-4339-87ba-d182865f9662",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inspecting data in Delta table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select  * from bronze.iot_measurements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9546730d-c156-4ead-bef0-50100fc35883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Table- to-table streams\n",
    "(Source table should be append only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c1beb90-0ace-4483-b38d-871bd00d7c55",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Table to table streams"
    }
   },
   "outputs": [],
   "source": [
    "dfstt=spark.readStream.table('iot_measurements')\\\n",
    "    .selectExpr('Measurements.Sensor as Sensor',\n",
    "           'Measurements.MeasurementType  as MeasurementType',\n",
    "           'cast(Measurements.MeasurementValue as float) as MeasurementValue',\n",
    "           'cast(EventTime as timestamp) as EventTime',\n",
    "           'Office','IngestionTimestamp')\\\n",
    "    .writeStream.format(\"delta\")\\\n",
    "    .queryName('iot_measurements_silver')\\\n",
    "    .option('checkpointLocation', checkpoint_path_sensor5)\\\n",
    "    .outputMode('append')\\\n",
    "    .toTable('silver.iot_measurements')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20322bfd-d693-42b0-b0b3-59c08da659a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver.iot_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f43d35-fe1b-410f-b0f8-df5e290ac4bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Managing the stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49a73b23-467a-4645-9115-444701def111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Managing execution flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28556053-697c-4af2-9c03-c6eff538986a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stopping stream"
    }
   },
   "outputs": [],
   "source": [
    "dfstt.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8439b538-66ce-4fcb-bd72-d9113c2a03eb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stopping all active streams"
    }
   },
   "outputs": [],
   "source": [
    "# strms.stop()\n",
    "\n",
    "for strm in spark.streams.active:\n",
    "    # print(strm.name)\n",
    "    strm.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ac44dce-97ea-4443-85c6-1b083c1f44e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfstt.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70d29e0a-088d-4227-ba56-b1447f70797c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Block execution flow"
    }
   },
   "outputs": [],
   "source": [
    "# strms.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35c0c71-f55b-49a9-b6ad-58bb7670b830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Trigger options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566b754e-b3d2-4beb-8f82-e7572e2555a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfWeather=spark.readStream.format('json') \\\n",
    "    .schema(weather_schema) \\\n",
    "    .load(f'{root_data_folder}/weather')\\\n",
    "    .withColumn('IngestionTimestamp', F.current_timestamp())\\\n",
    "    .withColumn('SourceFileName', F.input_file_name() )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c2973f7-94e6-44c8-8f7a-f0f745d21316",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fixed intervals"
    }
   },
   "outputs": [],
   "source": [
    "strmw=dfWeather.writeStream.format(\"delta\")\\\n",
    "    .trigger(processingTime='10 seconds')\\\n",
    "    .queryName('weather')\\\n",
    "    .option('checkpointLocation', checkpoint_path_weather)\\\n",
    "    .toTable('weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd96575d-4dc0-424e-a4ed-6671bbe67d50",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Process once (optional)"
    }
   },
   "outputs": [],
   "source": [
    "strms=dfSensor.writeStream.format(\"delta\")\\\n",
    "    .option('checkpointLocation', checkpoint_path_sensor2)\\\n",
    "    .trigger(availableNow=True)\\\n",
    "    .queryName('iot_measurements_once')\\\n",
    "    .toTable('bronze.iot_measurements_once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "032fbb49-0682-45e5-b9c7-e8171bb91c16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Source options\n",
    "- maxFilesPerTrigger\n",
    "- latestFirst\n",
    "(See https://spark.apache.org/docs/3.5.1/structured-streaming-programming-guide.html#input-sources for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaccf9d9-fef1-4943-aac6-916b41e3f54f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Limiting number of input files (optional, run as needed)"
    }
   },
   "outputs": [],
   "source": [
    "dfStrm = spark.readStream.format('json') \\\n",
    "    .schema(iot_schema) \\\n",
    "    .option('maxFilesPerTrigger', 5)\\\n",
    "    .option('latestFirst',True)\\\n",
    "    .load(f'{root_data_folder}/sensor')\\\n",
    "    .withColumn('IngestionTimestamp', F.current_timestamp())\\\n",
    "    .withColumn('SourceFileName', F.input_file_name())\n",
    "display(dfStrm)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce1c3677-aa71-41af-a569-f69ee026f11a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Source file cleaning options (archive,delete,off)"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Archiving option didn't work on UC volumes\n",
    "dfStrm = spark.readStream.format('json') \\\n",
    "    .schema(iot_schema) \\\n",
    "    .option(\"spark.sql.streaming.fileSource.log.compactInterval\",\"1\")\\\n",
    "    .option(\"spark.sql.streaming.fileSource.log.cleanupDelay\",\"1\")\\\n",
    "    .option('cleanSource', 'archive') \\\n",
    "    .option('sourceArchiveDir', root_archive_folder)\\\n",
    "    .load(f'{root_data_folder}/sensor')\\\n",
    "    .withColumn('IngestionTimestamp', F.current_timestamp())\\\n",
    "    .withColumn('SourceFileName', F.input_file_name())\\\n",
    "    .writeStream.format(\"delta\")\\\n",
    "    .option('checkpointLocation', checkpoint_path_sensor2)\\\n",
    "    .queryName('iot_measurements2')\\\n",
    "    .toTable('bronze.iot_measurements_archive')       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "274ec709-f145-45e8-8ce9-63dd1b7caab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(root_archive_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "461d609e-1961-4b07-8cab-53d79fa0ba5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sink options\n",
    "Output options: Append,update complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f1ebb8-bd39-47af-8133-7866f4e7be01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfSensorSilver=spark.readStream.table('silver.iot_measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "046766c0-91d2-4267-9135-6cdf091cf172",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Writing to memory sink"
    }
   },
   "outputs": [],
   "source": [
    "dfSensorSilver.writeStream.format(\"memory\")\\\n",
    "    .outputMode(\"update\")\\\n",
    "    .option('checkpointLocation', checkpoint_path_sensor3)\\\n",
    "    .queryName('iot_measurements_mem')\\\n",
    "    .start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "125d9ce5-ff6e-4403-ae00-047d796f0434",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Browsing memory sink"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from iot_measurements_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfbc06c3-ddc8-4e44-bac3-86051cb43d4c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using foreachBatch sink"
    }
   },
   "outputs": [],
   "source": [
    "def fn_batch_processing(df,batchid):\n",
    "    df.groupBy('Office','Sensor')\\\n",
    "        .pivot('MeasurementType',['temperature','humidity'])\\\n",
    "        .sum('MeasurementValue')\\\n",
    "        .write.mode('overwrite')\\\n",
    "        .saveAsTable('iot_pivoted')\n",
    "    pass    \n",
    "\n",
    "dfSensorSilver.writeStream\\\n",
    "    .option('checkpointLocation', checkpoint_path_sensor4)\\\n",
    "    .queryName('iot_measurements4')\\\n",
    "    .foreachBatch(fn_batch_processing)\\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdf3a9e5-c9c5-49dd-9fc7-9db5bc36193c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from iot_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5736ef20-014c-46ee-b7c0-4a04248fe7ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using foreach sink example"
    }
   },
   "outputs": [],
   "source": [
    "def persist_to_file(row):\n",
    "    file_path=f'{root_data_folder}/iot_agg/IoT_{row.Office}_{row.window.start}.txt'\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(str(row))\n",
    "    pass\n",
    "\n",
    "dfSensorSilver.withWatermark('EventTime','10 seconds')\\\n",
    "    .groupBy('Office',F.window('EventTime','1 hours'))\\\n",
    "    .agg(F.sum('MeasurementValue').alias('TotalValue'))\\\n",
    "    .writeStream.foreach(persist_to_file).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b976b7b3-f28d-4176-8249-86bfd05cff74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd9090e3-cdec-434c-81d0-b01f260c73ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select  * from weather "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fec1d2c-b13a-4cfb-a8a5-e341651dd5d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stateless transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "505ec2cf-b5fb-498d-9d52-5eae41e1a891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfb=spark.readStream.table('bronze.iot_measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "738d6250-10f8-40aa-939b-6245c1a6bb13",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Column projections and filters"
    }
   },
   "outputs": [],
   "source": [
    "dfso=dfb.selectExpr('cast(EventTime as Timestamp) as EventTime','Measurements.*','Office')\\\n",
    "   .filter('Office=\"Office 1\"')\n",
    "display(dfso)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e9cabf6-b4ab-4c51-af55-5acfea1f7fc1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stream deduplication"
    }
   },
   "outputs": [],
   "source": [
    "dfso=dfs.dropDuplicates('EventTime','Office','Sensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "859b40c2-b6e8-4670-b852-1a516eea0a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stateful transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "689aefdd-fa66-4311-ba1a-aba5b35a61d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4d29de5-b718-4647-af7a-f3dddef87f22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfSensorSilver = spark.readStream.table('silver.iot_measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47ca3a02-4785-474f-97be-42517804f4b7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Global aggregations"
    }
   },
   "outputs": [],
   "source": [
    "display(dfSensorSilver.groupBy().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09d339b9-0ef3-43b8-b5ed-5f8d3884bc1b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Grouped aggregations"
    }
   },
   "outputs": [],
   "source": [
    "dfso=dfSensorSilver.groupBy('Office','Sensor')\\\n",
    "    .agg(F.sum('MeasurementValue').alias('TotalValue'))\n",
    "display(dfso)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd16534a-386f-49f8-8a37-8c3b402cbb3c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Time-based aggregates"
    }
   },
   "outputs": [],
   "source": [
    "dfso=dfSensorSilver.groupBy('Office','Sensor',F.window('EventTime','1 hours'))\\\n",
    "    .agg(F.sum('MeasurementValue').alias('TotalValue'))\n",
    "dfso.writeStream.format('delta').option('checkpointLocation', checkpoint_path_sensor6)\\\n",
    "    .outputMode('complete')\\\n",
    "    .toTable('silver.timed_agg_iot_measurements')    \n",
    "# display(dfso)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c4d18f7-8146-48b4-b424-3ad19e9f7143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver.timed_agg_iot_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ad9a983-1d86-4579-9553-652cb6c98dc1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Allowing watermark delays"
    }
   },
   "outputs": [],
   "source": [
    "dfso=dfSensorSilver.withWatermark('EventTime','10 seconds')\\\n",
    "    .groupBy('Office','Sensor',F.window('EventTime','1 hours'))\\\n",
    "    .sum('MeasurementValue').alias('TotalValue')\n",
    "display(dfso)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dc3b294-047a-4a3c-8d5b-fe1c73c50866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Arbitrary state management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b820c1dd-8b09-4668-9aca-1ae64f7c27a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.streaming.state import GroupState, GroupStateTimeout\n",
    "from typing import Iterator, Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37bf856c-db4d-4de5-8311-65a984c4766a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfSensorSilver = spark.readStream.option('rowsPerBatch', '10')\\\n",
    "  .table('silver.iot_measurements')\n",
    "# display(dfSensorSilver)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7191b7ad-ac6d-45a1-a586-d7af1419e738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Basic state management "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3a5da49-fa80-4571-aa2f-a7011019d739",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Simple state management example"
    }
   },
   "outputs": [],
   "source": [
    "def custtom_agg(pkey: Tuple, dfi: Iterator[pd.DataFrame], state: GroupState) -> Iterator[pd.DataFrame]:\n",
    "      office_key,sensor_key=pkey\n",
    "      new_count=old_count=0\n",
    "      if state.exists:\n",
    "         old_count =state.get\n",
    "      for df in dfi:\n",
    "         new_count+=((df['MeasurementType']=='temperature') & (df['MeasurementValue']>23)).sum()\n",
    "      new_count+=old_count\n",
    "      state.update((new_count,))\n",
    "      yield pd.DataFrame({'office':[office_key],'sensor':[sensor_key],'count':[new_count]})\n",
    "\n",
    "output_schema = \"office STRING, sensor STRING,count LONG\"\n",
    "state_schema = \"count LONG\"\n",
    "dfa=dfSensorSilver.groupBy('Office','Sensor')\\\n",
    "  .applyInPandasWithState(custtom_agg,output_schema, state_schema, \"append\", GroupStateTimeout.NoTimeout)\n",
    "\n",
    "display(dfa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70157fce-c7dd-4cad-a8ef-4c68dfda86df",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Multi-value state management"
    }
   },
   "outputs": [],
   "source": [
    "def custtom_agg(pkey: Tuple, dfi: Iterator[pd.DataFrame], state: GroupState) -> Iterator[pd.DataFrame]:\n",
    "      #Receive old keys\n",
    "      office_key,sensor_key=pkey\n",
    "      new_temp=new_count_delta=new_alert=old_count=old_count_delta=old_alert=0\n",
    "      process_time=0\n",
    "      if state.exists:\n",
    "         old_process_time,old_count,old_count_delta,old_alert =state.get\n",
    "         process_time=state.getCurrentProcessingTimeMs()\n",
    "      for df in dfi:\n",
    "         new_count_delta+=((df['MeasurementType']=='temperature') & \n",
    "                     (df['MeasurementValue']>23)).sum()\n",
    "         \n",
    "         if new_count_delta>old_count_delta:\n",
    "            new_alert=1\n",
    "      total_count=new_count_delta+old_count\n",
    "      state.update((process_time,total_count,new_count_delta,new_alert))\n",
    "      yield pd.DataFrame({'office':[office_key],'sensor':[sensor_key], \n",
    "        'process_time':[process_time],'count':[total_count],\n",
    "        'count_delta':[new_count_delta],'alert':[new_alert]})\n",
    "\n",
    "\n",
    "output_schema = \"office STRING, sensor STRING,process_time LONG, count LONG,count_delta LONG,alert INT\"\n",
    "state_schema = \"process_time LONG,count LONG, count_delta LONG,alert INT\"\n",
    "dfa=dfSensorSilver.groupBy('Office','Sensor')\\\n",
    "  .applyInPandasWithState(custtom_agg,output_schema, state_schema, \"append\", GroupStateTimeout.NoTimeout)\n",
    "\n",
    "display(dfa.filter('Office=\"Office 1\"'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cae26dfb-d4f9-463c-a893-97d08ad4c185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cdd9cfb-8096-4c2c-950a-2e7d04eedd85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### State management with timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8591ce5c-5f2a-4e9a-9949-9deef3e7792d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "applyInPandasWithState with processing timeouts"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def custtom_agg(pkey: Tuple, dfi: Iterator[pd.DataFrame], state: GroupState) -> Iterator[pd.DataFrame]:\n",
    "    if state.hasTimedOut:\n",
    "        office_key, sensor_key = pkey\n",
    "        old_state = state.get[0]\n",
    "        state.remove()\n",
    "        yield pd.DataFrame({'office': [office_key], 'sensor': [sensor_key], 'count': [old_state]})\n",
    "    else:\n",
    "        count = old_state = 0\n",
    "        if state.exists:\n",
    "            old_state = state.get[0]\n",
    "        for df in dfi:\n",
    "            count += ((df['MeasurementType'] == 'temperature') & (df['MeasurementValue'] > 23)).sum()\n",
    "        new_state = count + old_state\n",
    "        state.update((new_state,))\n",
    "        state.setTimeoutDuration(1000)\n",
    "        yield pd.DataFrame()\n",
    "\n",
    "output_schema = \"office STRING, sensor STRING, count LONG\"\n",
    "state_schema = \"count LONG\"\n",
    "dfa = dfSensorSilver.withWatermark(\"EventTime\", \"5 seconds\")\\\n",
    "    .groupBy('Office', 'Sensor')\\\n",
    "    .applyInPandasWithState(custtom_agg, output_schema, state_schema, \"append\", \n",
    "                            GroupStateTimeout.ProcessingTimeTimeout)\\\n",
    "                          .writeStream.format('delta')\\\n",
    "                          .option(\"checkpointLocation\", checkpoint_path_sensor8)\\\n",
    "                          .queryName('agg_iot_measurements2')\\\n",
    "                          .toTable('silver.agg_iot_measurements')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983595bb-9795-4f87-9514-13c0ebd81819",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Event time based timeout"
    }
   },
   "outputs": [],
   "source": [
    "def custtom_agg(pkey: Tuple, dfi: Iterator[pd.DataFrame], state: GroupState) -> Iterator[pd.DataFrame]:\n",
    "    if state.hasTimedOut:\n",
    "        office_key, sensor_key = pkey\n",
    "        old_state = state.get[0]\n",
    "        state.remove()\n",
    "        yield pd.DataFrame({'office': [office_key], 'sensor': [sensor_key], 'count': [old_state]})\n",
    "    else:\n",
    "        count = old_state = 0\n",
    "        if state.exists:\n",
    "            old_state = state.get[0]\n",
    "        for df in dfi:\n",
    "            count += ((df['MeasurementType'] == 'temperature') & (df['MeasurementValue'] > 23)).sum()\n",
    "        new_state = count + old_state\n",
    "        state.update((new_state,))\n",
    "        state.setTimeoutTimestamp(2000)\n",
    "        yield pd.DataFrame()\n",
    "\n",
    "output_schema = \"office STRING, sensor STRING, count LONG\"\n",
    "state_schema = \"count LONG\"\n",
    "dfa = dfSensorSilver.withWatermark(\"EventTime\", \"5 seconds\")\\\n",
    "    .groupBy('Office', 'Sensor')\\\n",
    "    .applyInPandasWithState(custtom_agg, output_schema, state_schema, \"append\", \n",
    "                            GroupStateTimeout.EventTimeTimeout)\\\n",
    "                          .writeStream.format('delta')\\\n",
    "                          .option(\"checkpointLocation\", checkpoint_path_sensor8)\\\n",
    "                          .queryName('agg_iot_measurements')\\\n",
    "                          .toTable('silver.agg_iot_measurements')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "408bfd65-b12b-4f14-af69-17590007138f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver.agg_iot_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e9091e-8be6-487f-9239-e2a5a2172e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Stream joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc6c590b-0ceb-4502-b4b3-83a193d2bf9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Stream to static joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d087d599-2240-4fa1-8aec-0f33ec6272dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Caching on static dataframe is recommended\n",
    "dfo=spark.table('office').cache()   \n",
    "dfso=spark.readStream.table('silver.iot_measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec3fdb4-7a51-4a54-b9f9-c358d8bba4b1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stream to static joins"
    }
   },
   "outputs": [],
   "source": [
    "dfj=dfso.join(dfo, 'Office')\\\n",
    "  .select(dfso.EventTime,dfso.MeasurementType,dfso.MeasurementValue,\n",
    "          dfso.Office,dfso.Sensor,dfo.City)\n",
    "display(dfj)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ad99750-2e98-42ab-9b9e-88e95a3e5cbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Stream to stream joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1789d6f-5d2b-4e6f-9a5a-6f2e10ae454e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Watermarking requirements: **\n",
    "- Optional for inner joins\n",
    "- Mandatory for outer joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6277597b-f26d-4510-b22e-5c2872003a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Inner joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41495ba4-457d-4f70-b913-765b8d21c08c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.readStream.table('weather').withColumn('WeatherEventTime', F.col('EventTime').cast('Timestamp')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65530ec8-ce98-42c0-9267-1135c698b117",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inner join- precise match"
    }
   },
   "outputs": [],
   "source": [
    "dfwstm=spark.readStream.table('weather')\\\n",
    "    .withColumn('WeatherEventTime', F.col('EventTime').cast('Timestamp'))\\\n",
    "\n",
    "dfssj=dfj\\\n",
    "    .join(dfwstm,(dfj.City==dfwstm.City)  &  (dfj.EventTime == dfwstm.WeatherEventTime),how='inner')\\\n",
    "    .select(dfj.EventTime,'WeatherEventTime','MeasurementType','MeasurementValue','Office','Sensor',\n",
    "    dfj.City,dfwstm.Temperature)\n",
    "display(dfssj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1019983c-8521-4394-89f8-8ba8631c1b61",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inner joins"
    }
   },
   "outputs": [],
   "source": [
    "dfwstm=spark.readStream.table('weather')\\\n",
    "    .withColumn('WeatherEventTime', F.col('EventTime').cast('Timestamp'))\\\n",
    "\n",
    "dfssj=dfj\\\n",
    "    .join(dfwstm,\n",
    "    (dfj.City==dfwstm.City)  &\n",
    "    (dfj.EventTime.between(F.expr('WeatherEventTime - interval 15 seconds'), dfwstm.WeatherEventTime)),how='inner')\\\n",
    "    .select(dfj.EventTime,'WeatherEventTime','MeasurementType','MeasurementValue','Office','Sensor',\n",
    "    dfj.City,dfwstm.Temperature)\n",
    "display(dfssj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e323a6ee-f647-41fa-a1f9-7987592863f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Outer joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "838d6690-f1c8-4871-a5e3-1eae900d6254",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up watermarking delay"
    }
   },
   "outputs": [],
   "source": [
    "dfwstm=spark.readStream.table('weather')\\\n",
    "    .withColumn('WeatherEventTime', F.col('EventTime').cast('Timestamp'))\\\n",
    "    .drop('EventTime')\\\n",
    "    .withWatermark('WeatherEventTime','20 seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f9c8687-c1fc-46b4-b956-58fa46d2441f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Outer joins with time equailty condition"
    }
   },
   "outputs": [],
   "source": [
    "dfssj=dfj.withWatermark('EventTime','30 seconds')\\\n",
    "    .join(dfwstm,\n",
    "    (dfj.City==dfwstm.City)  &  (dfj.EventTime == dfwstm.WeatherEventTime),how='leftOuter')\\\n",
    "    .select(dfj.EventTime,'WeatherEventTime','MeasurementType','MeasurementValue','Office','Sensor',\n",
    "    dfj.City,dfwstm.Temperature)\n",
    "display(dfssj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651114a5-8190-490e-9b38-2451f5ec251e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stream to stream joins- time aproximity condition"
    }
   },
   "outputs": [],
   "source": [
    "dfssj=dfj.withWatermark('EventTime','5 seconds')\\\n",
    "    .join(dfwstm,\n",
    "    (dfj.City==dfwstm.City)  &\n",
    "    F.expr('EventTime BETWEEN WeatherEventTime - interval 15 seconds AND WeatherEventTime'),how='left')\\\n",
    "    .select(dfj.EventTime,'WeatherEventTime','MeasurementType','MeasurementValue','Office','Sensor',\n",
    "    dfj.City,dfwstm.Temperature)\n",
    "display(dfssj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "831f354f-fdbd-4697-8353-00a62a87da10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Monitoring stream execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b310a45-3ce5-4f7a-b2e8-b0d272be4d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfstt=spark.readStream.table('iot_measurements')\\\n",
    "    .selectExpr('Measurements.Sensor as Sensor',\n",
    "           'Measurements.MeasurementType  as MeasurementType',\n",
    "           'cast(Measurements.MeasurementValue as float) as MeasurementValue',\n",
    "           'cast(EventTime as timestamp) as EventTime',\n",
    "           'Office','IngestionTimestamp')\\\n",
    "    .writeStream.format(\"delta\")\\\n",
    "    .queryName('iot_measurements_silver')\\\n",
    "    .option('checkpointLocation', checkpoint_path_sensor5)\\\n",
    "    .outputMode('append')\\\n",
    "    .toTable('silver.iot_measurements')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e732266-b006-4de6-956c-95f7c1f86715",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get stream status"
    }
   },
   "outputs": [],
   "source": [
    "dfstt.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331ccc47-ceb9-474d-a695-3366e9ed2391",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read last ingestion"
    }
   },
   "outputs": [],
   "source": [
    "print(dfstt.lastProgress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bedadac2-93d9-45ac-882d-26c3331d20c9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading multiple runs history"
    }
   },
   "outputs": [],
   "source": [
    "dfstt.recentProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3ef6bc0-5f1a-4abb-8009-d2377db2f303",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List all active streams"
    }
   },
   "outputs": [],
   "source": [
    "for strm in spark.streams.active:\n",
    "    print(f'Stream {strm.name} is active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3900931-f485-4ae1-aec6-51f2221fc9ab",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using Spark Listener"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.streaming import StreamingQueryListener\n",
    "from pyspark.sql.streaming.listener import QueryStartedEvent, QueryProgressEvent, QueryIdleEvent, QueryTerminatedEvent\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "class MyListener(StreamingQueryListener):\n",
    "   def onQueryStarted(self, event: QueryStartedEvent) -> None:\n",
    "       # Do something with event.\n",
    "       print (\"Streaming progress listener started\")\n",
    "       pass\n",
    "\n",
    "   def onQueryProgress(self, event: QueryProgressEvent) -> None:\n",
    "        try:\n",
    "            schema = StructType([StructField(\"queryName\", StringType()), \n",
    "                                 StructField(\"batchId\", IntegerType()),\n",
    "                                 StructField(\"numInputRows\", IntegerType()),\n",
    "                                 StructField(\"inputRowsPerSecond\", FloatType()),\n",
    "                                 StructField(\"processedRowsPerSecond\", FloatType()),\n",
    "                                 StructField(\"batchDuration\", IntegerType()),\n",
    "                                 StructField(\"timestamp\", StringType())])\n",
    "            data={\"queryName\": event.progress.name,\n",
    "                \"batchId\":event.progress.batchId,\n",
    "                \"numInputRows\":event.progress.numInputRows,\n",
    "                \"inputRowsPerSecond\":event.progress.inputRowsPerSecond, \n",
    "                \"processedRowsPerSecond\":event.progress.processedRowsPerSecond,\n",
    "                \"batchDuration\":event.progress.batchDuration,\n",
    "                \"timestamp\":event.progress.timestamp}\n",
    "            df = spark.createDataFrame([data],schema)\n",
    "            print (\"Streaming progress writing to silver.streaming_monitor\")\n",
    "            df.write.mode(\"append\").saveAsTable(\"silver.streaming_monitor\")\n",
    "            # df.write.mode(\"append\").saveAsTable(\"learn_adb_fikrat.silver.streaming_monitor\")\n",
    "        except Exception as e:\n",
    "            print ('Streaming exception')\n",
    "            print (e)            \n",
    "        pass\n",
    "\n",
    "   def onQueryIdle(self, event: QueryIdleEvent) -> None:\n",
    "       # Do something with event.\n",
    "       pass\n",
    "\n",
    "   def onQueryTerminated(self, event: QueryTerminatedEvent) -> None:\n",
    "       # Do something with event.\n",
    "       pass\n",
    "\n",
    "spark.streams.addListener(MyListener())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3c03ec0-9abc-4e62-a03d-4eb5c5034453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (select * from silver.streaming_monitor order by queryname, `timestamp` desc) SELECT `timestamp`,AVG(`inputRowsPerSecond`) `column_55f8d82e89`,`batchId` FROM q GROUP BY `batchId`,`timestamp`",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "batchId",
             "id": "column_3e1a8ce5121"
            },
            "x": {
             "column": "timestamp",
             "id": "column_3e1a8ce5120"
            },
            "y": [
             {
              "column": "inputRowsPerSecond",
              "id": "column_55f8d82e89",
              "transform": "AVG"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numBins": 10,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_55f8d82e85": {
             "type": "line",
             "yAxis": 0
            },
            "column_55f8d82e89": {
             "type": "line",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "implicitDf": true,
        "rowLimit": 10000
       },
       "nuid": "c27c6a3c-798d-4512-9ace-d5307287a4e2",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.00738525390625,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "timestamp",
           "type": "column"
          },
          {
           "column": "batchId",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "timestamp",
           "type": "column"
          },
          {
           "alias": "column_55f8d82e89",
           "args": [
            {
             "column": "inputRowsPerSecond",
             "type": "column"
            }
           ],
           "function": "AVG",
           "type": "function"
          },
          {
           "column": "batchId",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from silver.streaming_monitor order by queryname, `timestamp` desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c687c448-1701-4eed-a178-2cc7aa2f41f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6529805702889019,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Mastering Spark Streaming",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
